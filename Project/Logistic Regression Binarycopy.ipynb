{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>201506_at</th>\n",
       "      <th>205486_at</th>\n",
       "      <th>216638_s_at</th>\n",
       "      <th>221619_s_at</th>\n",
       "      <th>221672_s_at</th>\n",
       "      <th>35148_at</th>\n",
       "      <th>Characteristics..Relapse..Metastasis.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.194502</td>\n",
       "      <td>-1.368737</td>\n",
       "      <td>-0.717225</td>\n",
       "      <td>-1.531878</td>\n",
       "      <td>0.389693</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.693175</td>\n",
       "      <td>-0.590901</td>\n",
       "      <td>-0.546195</td>\n",
       "      <td>0.037206</td>\n",
       "      <td>-0.128537</td>\n",
       "      <td>0.357764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333743</td>\n",
       "      <td>-0.739208</td>\n",
       "      <td>0.209520</td>\n",
       "      <td>0.644257</td>\n",
       "      <td>0.195022</td>\n",
       "      <td>0.387819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000242</td>\n",
       "      <td>-0.090453</td>\n",
       "      <td>1.383431</td>\n",
       "      <td>0.564629</td>\n",
       "      <td>0.031483</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.610597</td>\n",
       "      <td>-0.321874</td>\n",
       "      <td>-0.335347</td>\n",
       "      <td>-0.455115</td>\n",
       "      <td>-0.401555</td>\n",
       "      <td>-0.026012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>-1.250697</td>\n",
       "      <td>-0.169552</td>\n",
       "      <td>-0.780680</td>\n",
       "      <td>-1.270128</td>\n",
       "      <td>-2.083823</td>\n",
       "      <td>-1.229551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0.797979</td>\n",
       "      <td>-0.064454</td>\n",
       "      <td>0.313360</td>\n",
       "      <td>-0.489885</td>\n",
       "      <td>-1.616572</td>\n",
       "      <td>0.942426</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>-0.338362</td>\n",
       "      <td>2.031796</td>\n",
       "      <td>-0.930988</td>\n",
       "      <td>0.944626</td>\n",
       "      <td>-1.323058</td>\n",
       "      <td>0.286487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0.050661</td>\n",
       "      <td>0.274132</td>\n",
       "      <td>2.433399</td>\n",
       "      <td>-0.403539</td>\n",
       "      <td>-1.791106</td>\n",
       "      <td>-0.147379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>-1.265124</td>\n",
       "      <td>0.396863</td>\n",
       "      <td>-1.779709</td>\n",
       "      <td>1.719190</td>\n",
       "      <td>-0.786761</td>\n",
       "      <td>-1.524295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     201506_at  205486_at  216638_s_at  221619_s_at  221672_s_at  35148_at  \\\n",
       "0    -1.194502  -1.368737    -0.717225    -1.531878     0.389693  0.000420   \n",
       "1     0.693175  -0.590901    -0.546195     0.037206    -0.128537  0.357764   \n",
       "2     0.333743  -0.739208     0.209520     0.644257     0.195022  0.387819   \n",
       "3     1.000242  -0.090453     1.383431     0.564629     0.031483 -0.001509   \n",
       "4     0.610597  -0.321874    -0.335347    -0.455115    -0.401555 -0.026012   \n",
       "..         ...        ...          ...          ...          ...       ...   \n",
       "522  -1.250697  -0.169552    -0.780680    -1.270128    -2.083823 -1.229551   \n",
       "523   0.797979  -0.064454     0.313360    -0.489885    -1.616572  0.942426   \n",
       "524  -0.338362   2.031796    -0.930988     0.944626    -1.323058  0.286487   \n",
       "525   0.050661   0.274132     2.433399    -0.403539    -1.791106 -0.147379   \n",
       "526  -1.265124   0.396863    -1.779709     1.719190    -0.786761 -1.524295   \n",
       "\n",
       "     Characteristics..Relapse..Metastasis.  \n",
       "0                                        0  \n",
       "1                                        0  \n",
       "2                                        1  \n",
       "3                                        0  \n",
       "4                                        1  \n",
       "..                                     ...  \n",
       "522                                      0  \n",
       "523                                      0  \n",
       "524                                      0  \n",
       "525                                      0  \n",
       "526                                      0  \n",
       "\n",
       "[527 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 263 samples\n",
      "CV size: 158 samples\n",
      "Test size: 106 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([204,  59])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\Win\\Documents\\Github Workspace\\Machine_Learning\\Project\\Train Data.csv\"\n",
    "data = pd.read_csv(data_path, delimiter=\",\")\n",
    "\n",
    "display(data)\n",
    "\n",
    "# Separate features and label\n",
    "X = data.iloc[:, :-1]  # All columns except the last\n",
    "y = data.iloc[:, -1]   # The last column is assumed to be the label\n",
    "\n",
    "\n",
    "# # Step 1: Split into 50% train and 50% temp with stratification\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=42, stratify=y)\n",
    "\n",
    "# # Step 2: Split temp into 30% CV and 20% test (from 50% temp = 60/40 split)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.4, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Confirm split sizes\n",
    "print(f\"Train size: {len(X_train)} samples\")\n",
    "print(f\"CV size: {len(X_cv)} samples\")\n",
    "print(f\"Test size: {len(X_test)} samples\")\n",
    "\n",
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Summary saved to 'best_models_summary.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, recall_score, precision_score,\n",
    "    f1_score, accuracy_score\n",
    ")\n",
    "\n",
    "# Define gene names\n",
    "gene_names = ['201506_at', '205486_at', '216638_s_at', '221619_s_at', '221672_s_at', '35148_at']\n",
    "\n",
    "# Convert arrays to DataFrames\n",
    "X_train = pd.DataFrame(X_train, columns=gene_names)\n",
    "X_cv = pd.DataFrame(X_cv, columns=gene_names)\n",
    "X_test = pd.DataFrame(X_test, columns=gene_names)\n",
    "\n",
    "# Store all results\n",
    "all_results = []\n",
    "\n",
    "# Detect classification type\n",
    "n_classes = len(set(y_train))\n",
    "\n",
    "# Loop through all feature combinations\n",
    "for k in range(1, len(gene_names) + 1):\n",
    "    for comb in combinations(gene_names, k):\n",
    "        features = list(comb)\n",
    "\n",
    "        # Select features\n",
    "        X_train_sel = X_train[features]\n",
    "        X_cv_sel = X_cv[features]\n",
    "        X_test_sel = X_test[features]\n",
    "\n",
    "        # Train model\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        model.fit(X_train_sel, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_train_pred = model.predict(X_train_sel)\n",
    "        y_cv_pred = model.predict(X_cv_sel)\n",
    "        y_test_pred = model.predict(X_test_sel)\n",
    "        y_test_proba = model.predict_proba(X_test_sel)\n",
    "\n",
    "        # AUC handling\n",
    "        try:\n",
    "            if n_classes > 2:\n",
    "                auc = roc_auc_score(y_test, y_test_proba, multi_class='ovr', average='macro')\n",
    "            else:\n",
    "                auc = roc_auc_score(y_test, y_test_proba[:, 1])\n",
    "        except:\n",
    "            auc = float('-inf')\n",
    "\n",
    "        # Other metrics\n",
    "        recall = recall_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "        precision = precision_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        cv_acc = accuracy_score(y_cv, y_cv_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        all_results.append({\n",
    "            \"genes\": ' + '.join(features),\n",
    "            \"auc\": auc,\n",
    "            \"recall\": recall,\n",
    "            \"precision\": precision,\n",
    "            \"f1\": f1,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"cv_acc\": cv_acc,\n",
    "            \"test_acc\": test_acc\n",
    "        })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Get best model for each metric\n",
    "summary_rows = []\n",
    "metrics = {\n",
    "    \"Highest AUC\": \"auc\",\n",
    "    \"Highest Recall\": \"recall\",\n",
    "    \"Highest Precision\": \"precision\",\n",
    "    \"Highest F1-score\": \"f1\",\n",
    "    \"Highest Train Accuracy\": \"train_acc\",\n",
    "    \"Highest CV Accuracy\": \"cv_acc\",\n",
    "    \"Highest Test Accuracy\": \"test_acc\"\n",
    "}\n",
    "\n",
    "for label, metric in metrics.items():\n",
    "    best_row = results_df.loc[results_df[metric].idxmax()]\n",
    "    summary_rows.append({\n",
    "        \"Metric\": label,\n",
    "        \"Genes\": best_row[\"genes\"],\n",
    "        \"AUC\": best_row[\"auc\"],\n",
    "        \"Recall\": best_row[\"recall\"],\n",
    "        \"Precision\": best_row[\"precision\"],\n",
    "        \"F1-score\": best_row[\"f1\"],\n",
    "        \"Train Accuracy\": best_row[\"train_acc\"],\n",
    "        \"CV Accuracy\": best_row[\"cv_acc\"],\n",
    "        \"Test Accuracy\": best_row[\"test_acc\"]\n",
    "    })\n",
    "\n",
    "# Save summary to CSV\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.to_csv(\"best_models_summary.csv\", index=False)\n",
    "\n",
    "print(\"✅ Summary saved to 'best_models_summary.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
