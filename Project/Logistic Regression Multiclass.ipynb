{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>201506_at</th>\n",
       "      <th>205486_at</th>\n",
       "      <th>216638_s_at</th>\n",
       "      <th>221619_s_at</th>\n",
       "      <th>221672_s_at</th>\n",
       "      <th>35148_at</th>\n",
       "      <th>Characteristics..Relapse..Metastasis.Bone.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045283</td>\n",
       "      <td>0.088809</td>\n",
       "      <td>0.359098</td>\n",
       "      <td>0.015206</td>\n",
       "      <td>-0.912406</td>\n",
       "      <td>-1.800676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.875976</td>\n",
       "      <td>-0.041301</td>\n",
       "      <td>-0.111223</td>\n",
       "      <td>1.714917</td>\n",
       "      <td>-0.797470</td>\n",
       "      <td>-1.827605</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.223085</td>\n",
       "      <td>0.302113</td>\n",
       "      <td>-0.735687</td>\n",
       "      <td>0.131239</td>\n",
       "      <td>-1.416955</td>\n",
       "      <td>2.223924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.358691</td>\n",
       "      <td>-0.115612</td>\n",
       "      <td>-0.585816</td>\n",
       "      <td>1.431602</td>\n",
       "      <td>-1.310635</td>\n",
       "      <td>1.830601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.789431</td>\n",
       "      <td>0.038531</td>\n",
       "      <td>-1.340381</td>\n",
       "      <td>-0.756025</td>\n",
       "      <td>0.156410</td>\n",
       "      <td>-0.409375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0.949216</td>\n",
       "      <td>-0.344587</td>\n",
       "      <td>-0.185997</td>\n",
       "      <td>1.200971</td>\n",
       "      <td>-1.214392</td>\n",
       "      <td>-1.807650</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.632842</td>\n",
       "      <td>1.759387</td>\n",
       "      <td>1.620833</td>\n",
       "      <td>-0.697866</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>1.224772</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>-1.187681</td>\n",
       "      <td>-1.221904</td>\n",
       "      <td>-1.319973</td>\n",
       "      <td>-1.486159</td>\n",
       "      <td>0.195725</td>\n",
       "      <td>0.075763</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0.701818</td>\n",
       "      <td>0.278702</td>\n",
       "      <td>0.575100</td>\n",
       "      <td>0.047320</td>\n",
       "      <td>1.562932</td>\n",
       "      <td>0.313691</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>-1.320931</td>\n",
       "      <td>-0.463715</td>\n",
       "      <td>-0.461624</td>\n",
       "      <td>0.927184</td>\n",
       "      <td>0.394237</td>\n",
       "      <td>0.330682</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     201506_at  205486_at  216638_s_at  221619_s_at  221672_s_at  35148_at  \\\n",
       "0     0.045283   0.088809     0.359098     0.015206    -0.912406 -1.800676   \n",
       "1    -0.875976  -0.041301    -0.111223     1.714917    -0.797470 -1.827605   \n",
       "2     0.223085   0.302113    -0.735687     0.131239    -1.416955  2.223924   \n",
       "3     0.358691  -0.115612    -0.585816     1.431602    -1.310635  1.830601   \n",
       "4     0.789431   0.038531    -1.340381    -0.756025     0.156410 -0.409375   \n",
       "..         ...        ...          ...          ...          ...       ...   \n",
       "357   0.949216  -0.344587    -0.185997     1.200971    -1.214392 -1.807650   \n",
       "358   0.632842   1.759387     1.620833    -0.697866     0.004233  1.224772   \n",
       "359  -1.187681  -1.221904    -1.319973    -1.486159     0.195725  0.075763   \n",
       "360   0.701818   0.278702     0.575100     0.047320     1.562932  0.313691   \n",
       "361  -1.320931  -0.463715    -0.461624     0.927184     0.394237  0.330682   \n",
       "\n",
       "     Characteristics..Relapse..Metastasis.Bone.  \n",
       "0                                             1  \n",
       "1                                             1  \n",
       "2                                             0  \n",
       "3                                             1  \n",
       "4                                             1  \n",
       "..                                          ...  \n",
       "357                                           4  \n",
       "358                                           4  \n",
       "359                                           4  \n",
       "360                                           4  \n",
       "361                                           4  \n",
       "\n",
       "[362 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 181 samples\n",
      "CV size: 108 samples\n",
      "Test size: 73 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([148,  18,   9,   3,   3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_path = r\"C:\\Users\\Win\\Documents\\Github Workspace\\Machine_Learning\\Project\\emtab_bone_zscore.csv\"\n",
    "data_path = r\"C:\\Users\\Win\\Documents\\Github Workspace\\Machine_Learning\\Project\\Machine Learning Cancer - Data - Sheet1.csv\"\n",
    "data = pd.read_csv(data_path, delimiter=\",\")\n",
    "\n",
    "display(data)\n",
    "\n",
    "# Separate features and label\n",
    "X = data.iloc[:, :-1]  # All columns except the last\n",
    "y = data.iloc[:, -1]   # The last column is assumed to be the label\n",
    "\n",
    "\n",
    "# # Step 1: Split into 50% train and 50% temp with stratification\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=42, stratify=y)\n",
    "\n",
    "# # Step 2: Split temp into 30% CV and 20% test (from 50% temp = 60/40 split)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.4, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Confirm split sizes\n",
    "print(f\"Train size: {len(X_train)} samples\")\n",
    "print(f\"CV size: {len(X_cv)} samples\")\n",
    "print(f\"Test size: {len(X_test)} samples\")\n",
    "\n",
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.bincount(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Set Size: 1 ---\n",
      "\n",
      "Features: ['201506_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['216638_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['221619_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "--- Feature Set Size: 2 ---\n",
      "\n",
      "Features: ['201506_at', '205486_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '216638_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '221619_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '216638_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '221619_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['216638_s_at', '221619_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['216638_s_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['216638_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['221619_s_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['221619_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "--- Feature Set Size: 3 ---\n",
      "\n",
      "Features: ['201506_at', '205486_at', '216638_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '205486_at', '221619_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '205486_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '205486_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '216638_s_at', '221619_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '216638_s_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '216638_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '221619_s_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '221619_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '216638_s_at', '221619_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '216638_s_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '216638_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '221619_s_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '221619_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8356\n",
      "\n",
      "Features: ['216638_s_at', '221619_s_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['216638_s_at', '221619_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['216638_s_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['221619_s_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "--- Feature Set Size: 4 ---\n",
      "\n",
      "Features: ['201506_at', '205486_at', '216638_s_at', '221619_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '205486_at', '216638_s_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '205486_at', '216638_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '205486_at', '221619_s_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '205486_at', '221619_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '205486_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8356\n",
      "\n",
      "Features: ['201506_at', '216638_s_at', '221619_s_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '216638_s_at', '221619_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '216638_s_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '221619_s_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '216638_s_at', '221619_s_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '216638_s_at', '221619_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '216638_s_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8356\n",
      "\n",
      "Features: ['205486_at', '221619_s_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['216638_s_at', '221619_s_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "--- Feature Set Size: 5 ---\n",
      "\n",
      "Features: ['201506_at', '205486_at', '216638_s_at', '221619_s_at', '221672_s_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '205486_at', '216638_s_at', '221619_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '205486_at', '216638_s_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '205486_at', '221619_s_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['201506_at', '216638_s_at', '221619_s_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n",
      "\n",
      "Features: ['205486_at', '216638_s_at', '221619_s_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8082\n",
      "\n",
      "--- Feature Set Size: 6 ---\n",
      "\n",
      "Features: ['201506_at', '205486_at', '216638_s_at', '221619_s_at', '221672_s_at', '35148_at']\n",
      "Train Score:   0.8148\n",
      "CV Score:   0.8148\n",
      "Test Score: 0.8219\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Define feature names\n",
    "gene_names = ['201506_at', '205486_at', '216638_s_at', '221619_s_at', '221672_s_at', '35148_at']\n",
    "\n",
    "# Convert back to DataFrames if currently NumPy arrays\n",
    "X_train = pd.DataFrame(X_train, columns=gene_names)\n",
    "X_cv = pd.DataFrame(X_cv, columns=gene_names)\n",
    "X_test = pd.DataFrame(X_test, columns=gene_names)\n",
    "\n",
    "# Loop through all combinations\n",
    "for k in range(1, len(gene_names) + 1):\n",
    "    print(f\"\\n--- Feature Set Size: {k} ---\")\n",
    "    for comb in combinations(gene_names, k):\n",
    "        feature_list = list(comb)\n",
    "\n",
    "        # Select features\n",
    "        X_train_sel = X_train[feature_list]\n",
    "        X_cv_sel = X_cv[feature_list]\n",
    "        X_test_sel = X_test[feature_list]\n",
    "\n",
    "        # Train model\n",
    "        model = LogisticRegression(max_iter=100)\n",
    "        model.fit(X_train_sel, y_train)\n",
    "\n",
    "        # Evaluate\n",
    "        score_cv = model.score(X_cv_sel, y_cv)\n",
    "        score_test = model.score(X_test_sel, y_test)\n",
    "\n",
    "        # Output results\n",
    "        print(f\"\\nFeatures: {feature_list}\")\n",
    "        score_train = model.score(X_train_sel, y_train)\n",
    "        print(f\"Train Score:   {score_cv:.4f}\")\n",
    "        print(f\"CV Score:   {score_cv:.4f}\")\n",
    "        print(f\"Test Score: {score_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201506_at,0.5151898825811869,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "205486_at,0.4682655026133287,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "216638_s_at,0.45016855125550775,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "221619_s_at,0.4658046301524562,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "221672_s_at,0.42420796594709637,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "35148_at,0.332064071194506,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at,0.5046981279589975,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 216638_s_at,0.4548321243973418,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 221619_s_at,0.440316736403693,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 221672_s_at,0.43530701182875103,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 35148_at,0.3629386314168923,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "205486_at + 216638_s_at,0.500099369229804,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "205486_at + 221619_s_at,0.43962689484428613,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "205486_at + 221672_s_at,0.42920572181441746,0.2,0.1643835616438356,0.18045112781954886,0.8121546961325967,0.8148148148148148,0.821917808219178\n",
      "205486_at + 35148_at,0.3416990256120691,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "216638_s_at + 221619_s_at,0.3888876582354842,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "216638_s_at + 221672_s_at,0.4085180519963128,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "216638_s_at + 35148_at,0.2966622507926856,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "221619_s_at + 221672_s_at,0.4367918554875077,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "221619_s_at + 35148_at,0.4089380667641536,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "221672_s_at + 35148_at,0.3185334713595583,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 216638_s_at,0.4846312141964315,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 221619_s_at,0.43244733527342216,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 221672_s_at,0.42338096685922766,0.2,0.1643835616438356,0.18045112781954886,0.8121546961325967,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 35148_at,0.3548650624737582,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 216638_s_at + 221619_s_at,0.3743928293928294,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 216638_s_at + 221672_s_at,0.4088095962009005,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 216638_s_at + 35148_at,0.32286392351609744,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 221619_s_at + 221672_s_at,0.4543718117631161,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 221619_s_at + 35148_at,0.3891433204476683,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 221672_s_at + 35148_at,0.3484695739043565,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "205486_at + 216638_s_at + 221619_s_at,0.4292108374717071,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "205486_at + 216638_s_at + 221672_s_at,0.40873780808563415,0.2,0.1643835616438356,0.18045112781954886,0.8121546961325967,0.8148148148148148,0.821917808219178\n",
      "205486_at + 216638_s_at + 35148_at,0.3412622401752836,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "205486_at + 221619_s_at + 221672_s_at,0.417668925277621,0.2,0.1643835616438356,0.18045112781954886,0.8121546961325967,0.8148148148148148,0.821917808219178\n",
      "205486_at + 221619_s_at + 35148_at,0.3784687293382945,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "205486_at + 221672_s_at + 35148_at,0.36445067010284404,0.22857142857142856,0.3666666666666667,0.23181818181818184,0.8121546961325967,0.8148148148148148,0.8356164383561644\n",
      "216638_s_at + 221619_s_at + 221672_s_at,0.41388558301601786,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "216638_s_at + 221619_s_at + 35148_at,0.3218323705280227,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "216638_s_at + 221672_s_at + 35148_at,0.3359535874753266,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "221619_s_at + 221672_s_at + 35148_at,0.3787197585023672,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 216638_s_at + 221619_s_at,0.4157196185457055,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 216638_s_at + 221672_s_at,0.408360600751905,0.2,0.1643835616438356,0.18045112781954886,0.8121546961325967,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 216638_s_at + 35148_at,0.35057840710014626,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 221619_s_at + 221672_s_at,0.4304353617397096,0.2,0.1643835616438356,0.18045112781954886,0.8121546961325967,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 221619_s_at + 35148_at,0.3765123765123765,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 221672_s_at + 35148_at,0.37199049742528,0.22857142857142856,0.3666666666666667,0.23181818181818184,0.8121546961325967,0.8148148148148148,0.8356164383561644\n",
      "201506_at + 216638_s_at + 221619_s_at + 221672_s_at,0.40501503327590277,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 216638_s_at + 221619_s_at + 35148_at,0.3133485355224485,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 216638_s_at + 221672_s_at + 35148_at,0.3483223057136101,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 221619_s_at + 221672_s_at + 35148_at,0.37713296365470284,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "205486_at + 216638_s_at + 221619_s_at + 221672_s_at,0.4140849971284754,0.2,0.1643835616438356,0.18045112781954886,0.8121546961325967,0.8148148148148148,0.821917808219178\n",
      "205486_at + 216638_s_at + 221619_s_at + 35148_at,0.3756261130174174,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "205486_at + 216638_s_at + 221672_s_at + 35148_at,0.3585753859666903,0.22857142857142856,0.3666666666666667,0.23181818181818184,0.8121546961325967,0.8148148148148148,0.8356164383561644\n",
      "205486_at + 221619_s_at + 221672_s_at + 35148_at,0.3915681661333835,0.2,0.1643835616438356,0.18045112781954886,0.8121546961325967,0.8148148148148148,0.821917808219178\n",
      "216638_s_at + 221619_s_at + 221672_s_at + 35148_at,0.35828123567254005,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 216638_s_at + 221619_s_at + 221672_s_at,0.4060397332136462,0.2,0.1643835616438356,0.18045112781954886,0.8121546961325967,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 216638_s_at + 221619_s_at + 35148_at,0.3572574044313175,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 216638_s_at + 221672_s_at + 35148_at,0.36825198955633737,0.22523809523809524,0.2661971830985915,0.22459711620016964,0.8121546961325967,0.8148148148148148,0.821917808219178\n",
      "201506_at + 205486_at + 221619_s_at + 221672_s_at + 35148_at,0.39432352671483106,0.22523809523809524,0.2661971830985915,0.22459711620016964,0.8121546961325967,0.8148148148148148,0.821917808219178\n",
      "201506_at + 216638_s_at + 221619_s_at + 221672_s_at + 35148_at,0.3599830362873841,0.2,0.1643835616438356,0.18045112781954886,0.8176795580110497,0.8148148148148148,0.821917808219178\n",
      "205486_at + 216638_s_at + 221619_s_at + 221672_s_at + 35148_at,0.38085844107583233,0.19666666666666666,0.1638888888888889,0.17878787878787877,0.8176795580110497,0.8148148148148148,0.8082191780821918\n",
      "201506_at + 205486_at + 216638_s_at + 221619_s_at + 221672_s_at + 35148_at,0.3745281047454961,0.22523809523809524,0.2661971830985915,0.22459711620016964,0.8176795580110497,0.8148148148148148,0.821917808219178\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, recall_score, precision_score,\n",
    "    f1_score, accuracy_score\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "# Define feature names\n",
    "gene_names = ['201506_at', '205486_at', '216638_s_at', '221619_s_at', '221672_s_at', '35148_at']\n",
    "\n",
    "# Convert arrays to DataFrames (if needed)\n",
    "X_train = pd.DataFrame(X_train, columns=gene_names)\n",
    "X_cv = pd.DataFrame(X_cv, columns=gene_names)\n",
    "X_test = pd.DataFrame(X_test, columns=gene_names)\n",
    "\n",
    "# Loop through all combinations\n",
    "for k in range(1, len(gene_names) + 1):\n",
    "    for comb in combinations(gene_names, k):\n",
    "        feature_list = list(comb)\n",
    "\n",
    "        # Select features\n",
    "        X_train_sel = X_train[feature_list]\n",
    "        X_cv_sel = X_cv[feature_list]\n",
    "        X_test_sel = X_test[feature_list]\n",
    "\n",
    "        # Train model\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        model.fit(X_train_sel, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_train_pred = model.predict(X_train_sel)\n",
    "        y_cv_pred = model.predict(X_cv_sel)\n",
    "        y_test_pred = model.predict(X_test_sel)\n",
    "\n",
    "        # Probabilities for AUC (if supported)\n",
    "        y_test_proba = model.predict_proba(X_test_sel)\n",
    "\n",
    "        # Metrics\n",
    "        precision = precision_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "        recall = recall_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "\n",
    "        try:\n",
    "            auc = roc_auc_score(y_test, y_test_proba, multi_class='ovr', average='macro')\n",
    "        except ValueError:\n",
    "            auc = 'NA'\n",
    "\n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        cv_acc = accuracy_score(y_cv, y_cv_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        # Output\n",
    "        gene_str = ' + '.join(feature_list)\n",
    "        score_str = f\"{auc},{recall},{precision},{f1},{train_acc},{cv_acc},{test_acc}\"\n",
    "        print(f\"{gene_str},{score_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Summary saved to 'best_models_summary.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, recall_score, precision_score,\n",
    "    f1_score, accuracy_score\n",
    ")\n",
    "\n",
    "# Define gene names\n",
    "gene_names = ['201506_at', '205486_at', '216638_s_at', '221619_s_at', '221672_s_at', '35148_at']\n",
    "\n",
    "# Convert arrays to DataFrames\n",
    "X_train = pd.DataFrame(X_train, columns=gene_names)\n",
    "X_cv = pd.DataFrame(X_cv, columns=gene_names)\n",
    "X_test = pd.DataFrame(X_test, columns=gene_names)\n",
    "\n",
    "# Store all results\n",
    "all_results = []\n",
    "\n",
    "# Loop through all feature combinations\n",
    "for k in range(1, len(gene_names) + 1):\n",
    "    for comb in combinations(gene_names, k):\n",
    "        features = list(comb)\n",
    "\n",
    "        # Select features\n",
    "        X_train_sel = X_train[features]\n",
    "        X_cv_sel = X_cv[features]\n",
    "        X_test_sel = X_test[features]\n",
    "\n",
    "        # Train model\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        model.fit(X_train_sel, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_train_pred = model.predict(X_train_sel)\n",
    "        y_cv_pred = model.predict(X_cv_sel)\n",
    "        y_test_pred = model.predict(X_test_sel)\n",
    "        y_test_proba = model.predict_proba(X_test_sel)\n",
    "\n",
    "        # Metrics\n",
    "        try:\n",
    "            auc = roc_auc_score(y_test, y_test_proba, multi_class='ovr', average='macro')\n",
    "        except:\n",
    "            auc = float('-inf')\n",
    "\n",
    "        recall = recall_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "        precision = precision_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        cv_acc = accuracy_score(y_cv, y_cv_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        all_results.append({\n",
    "            \"genes\": ' + '.join(features),\n",
    "            \"auc\": auc,\n",
    "            \"recall\": recall,\n",
    "            \"precision\": precision,\n",
    "            \"f1\": f1,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"cv_acc\": cv_acc,\n",
    "            \"test_acc\": test_acc\n",
    "        })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Get best model for each metric\n",
    "summary_rows = []\n",
    "metrics = {\n",
    "    \"Highest AUC\": \"auc\",\n",
    "    \"Highest Recall\": \"recall\",\n",
    "    \"Highest Precision\": \"precision\",\n",
    "    \"Highest F1-score\": \"f1\",\n",
    "    \"Highest Train Accuracy\": \"train_acc\",\n",
    "    \"Highest CV Accuracy\": \"cv_acc\",\n",
    "    \"Highest Test Accuracy\": \"test_acc\"\n",
    "}\n",
    "\n",
    "for label, metric in metrics.items():\n",
    "    best_row = results_df.loc[results_df[metric].idxmax()]\n",
    "    summary_rows.append({\n",
    "        \"Metric\": label,\n",
    "        \"Genes\": best_row[\"genes\"],\n",
    "        \"AUC\": best_row[\"auc\"],\n",
    "        \"Recall\": best_row[\"recall\"],\n",
    "        \"Precision\": best_row[\"precision\"],\n",
    "        \"F1-score\": best_row[\"f1\"],\n",
    "        \"Train Accuracy\": best_row[\"train_acc\"],\n",
    "        \"CV Accuracy\": best_row[\"cv_acc\"],\n",
    "        \"Test Accuracy\": best_row[\"test_acc\"]\n",
    "    })\n",
    "\n",
    "# Save to CSV\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.to_csv(\"best_models_summary.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Summary saved to 'best_models_summary.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
